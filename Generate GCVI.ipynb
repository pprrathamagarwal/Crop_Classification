{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCntwp7jvBZ-"
   },
   "source": [
    "## Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2420,
     "status": "ok",
     "timestamp": 1700212551099,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "Jkly4lhevDok"
   },
   "outputs": [],
   "source": [
    "import geemap\n",
    "import geopandas as gpd\n",
    "from pprint import pprint\n",
    "import ee\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBg2jArDvSv3"
   },
   "source": [
    "## Authenticate to Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "executionInfo": {
     "elapsed": 42023,
     "status": "ok",
     "timestamp": 1700212792076,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "GXSXdKfivbFF",
    "outputId": "a942c21b-9630-4261-8bd0-5d390f6b2097"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee.Authenticate() #Uncomment this whenever needed, once done usually not needed for 1-2 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 2555,
     "status": "ok",
     "timestamp": 1700212798099,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "NK6QSWMvveBt",
    "outputId": "7f7f3e76-bca2-4cde-829e-ee55e4a9e36f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ee.Initialize(project='proj76')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jL3Anh2eFPkw"
   },
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZ8WE4iQM9Dy"
   },
   "source": [
    "## Defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1700212615196,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "U1CKZDHZMnS4",
    "outputId": "f0ee5734-86a4-476b-f40e-d20289348c82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chastainBandNames = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']\n",
    "\n",
    "# Regression model parameters from Table-4. MSI TOA reflectance as a function of OLI TOA reflectance.\n",
    "msiOLISlopes = [1.0946,1.0043,1.0524,0.8954,1.0049,1.0002]\n",
    "msiOLIIntercepts = [-0.0107,0.0026,-0.0015,0.0033,0.0065,0.0046]\n",
    "\n",
    "# Regression model parameters from Table-5. MSI TOA reflectance as a function of ETM+ TOA reflectance.\n",
    "msiETMSlopes = [1.10601,0.99091,1.05681,1.0045,1.03611,1.04011]\n",
    "msiETMIntercepts = [-0.0139,0.00411,-0.0024,-0.0076,0.00411,0.00861]\n",
    "\n",
    "# Regression model parameters from Table-6. OLI TOA reflectance as a function of ETM+ TOA reflectance.\n",
    "oliETMSlopes =[1.03501,1.00921,1.01991,1.14061,1.04351,1.05271];\n",
    "oliETMIntercepts = [-0.0055,-0.0008,-0.0021,-0.0163,-0.0045,0.00261]\n",
    "\n",
    "# Construct dictionary to handle all pairwise combos\n",
    "chastainCoeffDict = { 'MSI_OLI':[msiOLISlopes,msiOLIIntercepts,1], # check what the third item corresponds to\n",
    "                      'MSI_ETM':[msiETMSlopes,msiETMIntercepts,1],\n",
    "                      'OLI_ETM':[oliETMSlopes,oliETMIntercepts,1],\n",
    "                      'OLI_MSI':[msiOLISlopes,msiOLIIntercepts,0],\n",
    "                      'ETM_MSI':[msiETMSlopes,msiETMIntercepts,0],\n",
    "                      'ETM_OLI':[oliETMSlopes,oliETMIntercepts,0]\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC4aKxunNBvn"
   },
   "source": [
    "## Function defnitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1700212724455,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "8PEuScIlKrfi",
    "outputId": "2f325424-8476-4572-ca00-ded37e18c5a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Function to mask cloudy pixels in Landsat-7\n",
    "'''\n",
    "'''\n",
    "Function to mask cloudy pixels in Landsat-7\n",
    "'''\n",
    "def maskl8cloud(image):\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    cloud_mask = qa.bitwiseAnd(1 << 4).eq(0).And(qa.bitwiseAnd(1 << 5).eq(0))\n",
    "    return image.updateMask(cloud_mask).select(\n",
    "        ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "    ).rename(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "\n",
    "def maskl7cloud(image):\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    cloud_mask = qa.bitwiseAnd(1 << 4).eq(0).And(qa.bitwiseAnd(1 << 5).eq(0))\n",
    "    return image.updateMask(cloud_mask).select(\n",
    "        ['B1', 'B2', 'B3', 'B4', 'B5', 'B7']\n",
    "    ).rename(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "\n",
    "def masks2cloud(image):\n",
    "    cloud_prob = image.select('MSK_CLDPRB')\n",
    "    mask = cloud_prob.lt(20)  # Cloud probability < 20%\n",
    "    return image.select(\n",
    "        ['B2', 'B3', 'B4', 'B8', 'B11', 'B12']\n",
    "    ).rename(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']).updateMask(mask)\n",
    "\n",
    "'''\n",
    "Sensor Harmonization Configuration (Updated for TOA)\n",
    "'''\n",
    "# Band names matching TOA collections\n",
    "chastainBandNames = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']\n",
    "\n",
    "'''\n",
    "Get Landsat and Sentinel image collections\n",
    "'''\n",
    "def Get_L7_L8_S2_ImageCollections(inputStartDate, inputEndDate, roi_boundary):\n",
    "  # ------ Landsat 7 TOA\n",
    "  L7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_TOA') \\\n",
    "          .filterDate(inputStartDate, inputEndDate) \\\n",
    "          .filterBounds(roi_boundary) \\\n",
    "          .map(maskl7cloud)\n",
    "  # print('\\n Original Landsat 7 TOA dataset: \\n',L7.limit(1).getInfo())\n",
    "  # print('Number of images in Landsat 7 TOA dataset: \\t',L7.size().getInfo())\n",
    "\n",
    "  # ------ Landsat 8 TOA\n",
    "  L8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA') \\\n",
    "          .filterDate(inputStartDate, inputEndDate) \\\n",
    "          .filterBounds(roi_boundary) \\\n",
    "          .map(maskl8cloud)\n",
    "  # print('\\n Original Landsat 8 TOA dataset: \\n', L8.limit(1).getInfo())\n",
    "  # print('Number of images in Landsat 8 TOA dataset: \\t',L8.size().getInfo())\n",
    "\n",
    "  # ------ Sentinel-2 TOA\n",
    "  S2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
    "          .filterDate(inputStartDate, inputEndDate) \\\n",
    "          .filterBounds(roi_boundary)  \\\n",
    "          .map(masks2cloud)\n",
    "  # print('\\n Original Sentinel-2 TOA dataset: \\n',S2.limit(1).getInfo())\n",
    "  # print('Number of images in Sentinel 2 TOA dataset: \\t',S2.size().getInfo())\n",
    "\n",
    "  return L7, L8, S2\n",
    "\n",
    "\n",
    "'''\n",
    "Function to apply model in one direction\n",
    "'''\n",
    "def dir0Regression(img,slopes,intercepts):\n",
    "  return img.select(chastainBandNames).multiply(slopes).add(intercepts)\n",
    "\n",
    "\n",
    "'''\n",
    "Applying the model in the opposite direction\n",
    "'''\n",
    "def dir1Regression(img,slopes,intercepts):\n",
    "  return img.select(chastainBandNames).subtract(intercepts).divide(slopes)\n",
    "\n",
    "\n",
    "'''\n",
    "Function to correct one sensor to another\n",
    "'''\n",
    "def harmonizationChastain(img, fromSensor,toSensor):\n",
    "  # Get the model for the given from and to sensor\n",
    "  comboKey = fromSensor.upper() + '_' + toSensor.upper()\n",
    "  coeffList = chastainCoeffDict[comboKey]\n",
    "  slopes = coeffList[0]\n",
    "  intercepts = coeffList[1]\n",
    "  direction = ee.Number(coeffList[2])\n",
    "\n",
    "  # Apply the model in the respective direction\n",
    "  out = ee.Algorithms.If(direction.eq(0),dir0Regression(img,slopes,intercepts),dir1Regression(img,slopes,intercepts))\n",
    "  return ee.Image(out).copyProperties(img).copyProperties(img,['system:time_start'])\n",
    "\n",
    "\n",
    "'''\n",
    "Calibrate Landsat-8 (OLI) and Sentinel-2 (MSI) to Landsat-7 (ETM+)\n",
    "'''\n",
    "def Harmonize_L7_L8_S2(L7, L8, S2):\n",
    "  # harmonization\n",
    "  harmonized_L8 = L8.map( lambda img: harmonizationChastain(img, 'OLI','ETM') )\n",
    "  harmonized_S2 = S2.map( lambda img: harmonizationChastain(img, 'MSI','ETM') )\n",
    "\n",
    "  # Merge harmonized landsat-8 and sentinel-2 to landsat-7 image collection\n",
    "  harmonized_LandsatSentinel_ic = ee.ImageCollection(L7.merge(harmonized_L8).merge(harmonized_S2))\n",
    "  # print(harmonized_LandsatSentinel_ic.size().getInfo())\n",
    "  return harmonized_LandsatSentinel_ic\n",
    "\n",
    "\n",
    "'''\n",
    "Add NDVI band to harmonized image collection\n",
    "'''\n",
    "def addNDVI(image):\n",
    "  return image.addBands(image.normalizedDifference(['NIR', 'RED']).rename('NDVI')).float()\n",
    "\n",
    "\n",
    "'''\n",
    "Function definitions to get NDVI values at each 16-day composites\n",
    "'''\n",
    "def Get_NDVI_image_datewise(harmonized_LS_ic):\n",
    "  def get_NDVI_datewise(date):\n",
    "    return harmonized_LS_ic.select(['NDVI']) \\\n",
    "                            .filterDate(ee.Date(date), ee.Date(date).advance(16, 'day')) \\\n",
    "                            .median() \\\n",
    "                            .set('system:time_start',ee.Date(date).millis())\n",
    "  return get_NDVI_datewise\n",
    "\n",
    "def Get_LS_16Day_NDVI_TimeSeries(inputStartDate, inputEndDate, harmonized_LS_ic):\n",
    "  startDate = datetime.strptime(inputStartDate,\"%Y-%m-%d\")\n",
    "  endDate = datetime.strptime(inputEndDate,\"%Y-%m-%d\")\n",
    "\n",
    "  date_list = pd.date_range(start=startDate, end=endDate, freq='5D').tolist()\n",
    "  date_list = ee.List( [datetime.strftime(curr_date,\"%Y-%m-%d\") for curr_date in date_list] )\n",
    "\n",
    "  LSC =  ee.ImageCollection.fromImages(date_list.map(Get_NDVI_image_datewise(harmonized_LS_ic)))\n",
    "\n",
    "  return LSC\n",
    "\n",
    "\n",
    "'''\n",
    "Pair available LSC and modis values for each time stamp.\n",
    "'''\n",
    "def pairLSModis(lsRenameBands):\n",
    "  def pair(feature):\n",
    "    date = ee.Date( feature.get('system:time_start') )\n",
    "    startDateT = date.advance(-8,'day')\n",
    "    endDateT = date.advance(8,'day')\n",
    "\n",
    "    # ------ MODIS VI ( We can add EVI to the band list later )\n",
    "    modis = ee.ImageCollection('MODIS/061/MOD13Q1') \\\n",
    "              .filterDate(startDateT, endDateT) \\\n",
    "              .select(['NDVI','SummaryQA']) \\\n",
    "              .filterBounds(roi_boundary) \\\n",
    "              .median() \\\n",
    "              .rename(['NDVI_modis', 'SummaryQA_modis'])\n",
    "\n",
    "    return feature.rename(lsRenameBands).addBands(modis)\n",
    "  return pair\n",
    "\n",
    "\n",
    "'''\n",
    "Function to get Pearson Correlation Coffecient to perform GapFilling\n",
    "'''\n",
    "def get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, bandList):\n",
    "  corr = LSC_modis_paired_ic.filterBounds(roi_boundary) \\\n",
    "                            .select(bandList).toArray() \\\n",
    "                            .arrayReduce( reducer = ee.Reducer.pearsonsCorrelation(), axes=[0], fieldAxis=1 ) \\\n",
    "                            .arrayProject([1]).arrayFlatten([['c', 'p']])\n",
    "  return corr\n",
    "\n",
    "\n",
    "'''\n",
    "Fill gaps in LSC timeseries using modis data\n",
    "'''\n",
    "def gapfillLSM(LSC_modis_regression_model, LSC_bandName, modis_bandName):\n",
    "  def peformGapfilling(image):\n",
    "    offset = LSC_modis_regression_model.select('offset')\n",
    "    scale = LSC_modis_regression_model.select('scale')\n",
    "    nodata = -1\n",
    "\n",
    "    lsc_image = image.select(LSC_bandName)\n",
    "    modisfit = image.select(modis_bandName).multiply(scale).add(offset)\n",
    "\n",
    "    mask = lsc_image.mask()#update mask needs an input (no default input from the API document)\n",
    "    gapfill = lsc_image.unmask(nodata)\n",
    "    gapfill = gapfill.where(mask.Not(), modisfit)\n",
    "\n",
    "    '''\n",
    "    in SummaryQA,\n",
    "    0: Good data, use with confidence\n",
    "    1: Marginal data, useful but look at detailed QA for more information\n",
    "    2: Pixel covered with snow/ice\n",
    "    3: Pixel is cloudy\n",
    "    '''\n",
    "    qc_m = image.select('SummaryQA_modis').unmask(3)  # missing value is grouped as cloud\n",
    "    w_m  = modisfit.mask().rename('w_m').where(qc_m.eq(0), 0.8)  # default is 0.8\n",
    "    w_m = w_m.where(qc_m.eq(1), 0.5)   # Marginal\n",
    "    w_m = w_m.where(qc_m.gte(2), 0.2) # snow/ice or cloudy\n",
    "\n",
    "    # make sure these modis values are read where there is missing data from LandSat, Sentinel\n",
    "    w_l = gapfill.mask() # default is 1\n",
    "    w_l = w_l.where(mask.Not(), w_m)\n",
    "\n",
    "    return gapfill.addBands(w_l).rename(['gapfilled_'+LSC_bandName,'SummaryQA']) #have NDVI from modis and a summary of clarity for each\n",
    "\n",
    "  return peformGapfilling\n",
    "\n",
    "\n",
    "'''\n",
    "Function to combine LSC with Modis data\n",
    "'''\n",
    "def Combine_LS_Modis(LSC):\n",
    "  lsRenameBands = ee.Image(LSC.first()).bandNames().map( lambda band: ee.String(band).cat('_lsc') )\n",
    "  LSC_modis_paired_ic = LSC.map( pairLSModis(lsRenameBands) )\n",
    "\n",
    "  # Output contains scale, offset i.e. two bands\n",
    "  LSC_modis_regression_model_NDVI = LSC_modis_paired_ic.select(['NDVI_modis', 'NDVI_lsc']) \\\n",
    "                                                        .reduce(ee.Reducer.linearFit())\n",
    "\n",
    "  corr_NDVI = get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, ['NDVI_modis', 'NDVI_lsc'])\n",
    "  LSMC_NDVI = LSC_modis_paired_ic.map(gapfillLSM(LSC_modis_regression_model_NDVI, 'NDVI_lsc', 'NDVI_modis'))\n",
    "\n",
    "  return LSMC_NDVI\n",
    "\n",
    "\n",
    "'''\n",
    "Mask out low quality pixels\n",
    "'''\n",
    "def mask_low_QA(lsmc_image):\n",
    "  low_qa = lsmc_image.select('SummaryQA').neq(0.2)\n",
    "  return lsmc_image.updateMask(low_qa).copyProperties(lsmc_image, ['system:time_start'])\n",
    "\n",
    "\n",
    "'''\n",
    "Add image timestamp to each image in time series\n",
    "'''\n",
    "def add_timestamp(image):\n",
    "  timeImage = image.metadata('system:time_start').rename('timestamp')\n",
    "  timeImageMasked = timeImage.updateMask(image.mask().select(0))\n",
    "  return image.addBands(timeImageMasked)\n",
    "\n",
    "\n",
    "'''\n",
    "Perform linear interpolation on missing values\n",
    "'''\n",
    "def performInterpolation(image):\n",
    "  image = ee.Image(image)\n",
    "  beforeImages = ee.List(image.get('before'))\n",
    "  beforeMosaic = ee.ImageCollection.fromImages(beforeImages).mosaic()\n",
    "  afterImages = ee.List(image.get('after'))\n",
    "  afterMosaic = ee.ImageCollection.fromImages(afterImages).mosaic()\n",
    "\n",
    "  # Interpolation formula\n",
    "  # y = y1 + (y2-y1)*((t – t1) / (t2 – t1))\n",
    "  # y = interpolated image\n",
    "  # y1 = before image\n",
    "  # y2 = after image\n",
    "  # t = interpolation timestamp\n",
    "  # t1 = before image timestamp\n",
    "  # t2 = after image timestamp\n",
    "\n",
    "  t1 = beforeMosaic.select('timestamp').rename('t1')\n",
    "  t2 = afterMosaic.select('timestamp').rename('t2')\n",
    "  t = image.metadata('system:time_start').rename('t')\n",
    "  timeImage = ee.Image.cat([t1, t2, t])\n",
    "  timeRatio = timeImage.expression('(t - t1) / (t2 - t1)', {\n",
    "                  't': timeImage.select('t'),\n",
    "                  't1': timeImage.select('t1'),\n",
    "                  't2': timeImage.select('t2'),\n",
    "              })\n",
    "\n",
    "  interpolated = beforeMosaic.add((afterMosaic.subtract(beforeMosaic).multiply(timeRatio)))\n",
    "  result = image.unmask(interpolated)\n",
    "  fill_value = ee.ImageCollection([beforeMosaic, afterMosaic]).mosaic()\n",
    "  result = result.unmask(fill_value)\n",
    "\n",
    "  return result.copyProperties(image, ['system:time_start'])\n",
    "\n",
    "\n",
    "def interpolate_timeseries(S1_TS):\n",
    "  lsmc_masked = S1_TS.map(mask_low_QA)\n",
    "  filtered = lsmc_masked.map(add_timestamp)\n",
    "\n",
    "  # Time window in which we are willing to look forward and backward for unmasked pixel in time series\n",
    "  timeWindow = 120\n",
    "\n",
    "  # Define a maxDifference filter to find all images within the specified days. Convert days to milliseconds.\n",
    "  millis = ee.Number(timeWindow).multiply(1000*60*60*24)\n",
    "  # Filter says that pick only those timestamps which lie between the 2 timestamps not more than millis difference apart\n",
    "  maxDiffFilter = ee.Filter.maxDifference(\n",
    "                              difference = millis,\n",
    "                              leftField = 'system:time_start',\n",
    "                              rightField = 'system:time_start',\n",
    "                            )\n",
    "\n",
    "  # Filter to find all images after a given image. Compare the image's timstamp against other images.\n",
    "  # Images ahead of target image should have higher timestamp.\n",
    "  lessEqFilter = ee.Filter.lessThanOrEquals(\n",
    "                            leftField = 'system:time_start',\n",
    "                            rightField = 'system:time_start'\n",
    "                          )\n",
    "\n",
    "  # Similarly define this filter to find all images before a given image\n",
    "  greaterEqFilter = ee.Filter.greaterThanOrEquals(\n",
    "                            leftField = 'system:time_start',\n",
    "                            rightField = 'system:time_start'\n",
    "                          )\n",
    "\n",
    "  # Apply first join to find all images that are after the target image but within the timeWindow\n",
    "  filter1 = ee.Filter.And( maxDiffFilter, lessEqFilter )\n",
    "  join1 = ee.Join.saveAll(\n",
    "                  matchesKey = 'after',\n",
    "                  ordering = 'system:time_start',\n",
    "                  ascending = False\n",
    "          )\n",
    "  join1Result = join1.apply(\n",
    "                  primary = filtered,\n",
    "                  secondary = filtered,\n",
    "                  condition = filter1\n",
    "                )\n",
    "\n",
    "  # Apply first join to find all images that are after the target image but within the timeWindow\n",
    "  filter2 = ee.Filter.And( maxDiffFilter, greaterEqFilter )\n",
    "  join2 = ee.Join.saveAll(\n",
    "                  matchesKey = 'before',\n",
    "                  ordering = 'system:time_start',\n",
    "                  ascending = True\n",
    "          )\n",
    "  join2Result = join2.apply(\n",
    "                  primary = join1Result,\n",
    "                  secondary = join1Result,\n",
    "                  condition = filter2\n",
    "                )\n",
    "\n",
    "  interpolated_S1_TS = ee.ImageCollection(join2Result.map(performInterpolation))\n",
    "\n",
    "  return interpolated_S1_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chastainBandNames = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']\n",
    "\n",
    "# Regression model parameters from Table-4. MSI TOA reflectance as a function of OLI TOA reflectance.\n",
    "msiOLISlopes = [1.0946,1.0043,1.0524,0.8954,1.0049,1.0002]\n",
    "msiOLIIntercepts = [-0.0107,0.0026,-0.0015,0.0033,0.0065,0.0046]\n",
    "\n",
    "# Regression model parameters from Table-5. MSI TOA reflectance as a function of ETM+ TOA reflectance.\n",
    "msiETMSlopes = [1.10601,0.99091,1.05681,1.0045,1.03611,1.04011]\n",
    "msiETMIntercepts = [-0.0139,0.00411,-0.0024,-0.0076,0.00411,0.00861]\n",
    "\n",
    "# Regression model parameters from Table-6. OLI TOA reflectance as a function of ETM+ TOA reflectance.\n",
    "oliETMSlopes =[1.03501,1.00921,1.01991,1.14061,1.04351,1.05271];\n",
    "oliETMIntercepts = [-0.0055,-0.0008,-0.0021,-0.0163,-0.0045,0.00261]\n",
    "\n",
    "# Construct dictionary to handle all pairwise combos\n",
    "chastainCoeffDict = { 'MSI_OLI':[msiOLISlopes,msiOLIIntercepts,1], # check what the third item corresponds to\n",
    "                      'MSI_ETM':[msiETMSlopes,msiETMIntercepts,1],\n",
    "                      'OLI_ETM':[oliETMSlopes,oliETMIntercepts,1],\n",
    "                      'OLI_MSI':[msiOLISlopes,msiOLIIntercepts,0],\n",
    "                      'ETM_MSI':[msiETMSlopes,msiETMIntercepts,0],\n",
    "                      'ETM_OLI':[oliETMSlopes,oliETMIntercepts,0]\n",
    "                    }\n",
    "\n",
    "\n",
    "'''\n",
    "Function to mask cloudy pixels in Landsat-7\n",
    "'''\n",
    "def maskL7cloud(image):\n",
    "  qa = image.select('QA_PIXEL')\n",
    "  mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "  return image.updateMask(mask).select(['B1', 'B2', 'B3' , 'B4' , 'B5' , 'B7']).rename('BLUE', 'GREEN', 'RED' , 'NIR' , 'SWIR1' , 'SWIR2')\n",
    "\n",
    "\n",
    "'''\n",
    "Function to mask cloudy pixels in Landsat-8\n",
    "'''\n",
    "def maskL8cloud(image):\n",
    "  qa = image.select('QA_PIXEL')\n",
    "  mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "  return image.updateMask(mask).select(['B2', 'B3', 'B4' , 'B5' , 'B6' , 'B7']).rename('BLUE', 'GREEN', 'RED' , 'NIR' , 'SWIR1' , 'SWIR2')\n",
    "\n",
    "\n",
    "'''\n",
    "Function to mask clouds using the quality band of Sentinel-2 TOA\n",
    "'''\n",
    "def maskS2cloudTOA(image):\n",
    "  qa = image.select('QA60')\n",
    "  # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "  cloudBitMask = 1 << 10\n",
    "  cirrusBitMask = 1 << 11\n",
    "  # Both flags should be set to zero, indicating clear conditions.\n",
    "  mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0));\n",
    "  return image.updateMask(mask).select(['B2', 'B3', 'B4', 'B8',  'B11', 'B12']).rename(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "\n",
    "\n",
    "'''\n",
    "Get Landsat and Sentinel image collections\n",
    "'''\n",
    "def Get_L7_L8_S2_ImageCollections(inputStartDate, inputEndDate, roi_boundary):\n",
    "  # ------ Landsat 7 TOA\n",
    "  L7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_TOA') \\\n",
    "          .filterDate(inputStartDate, inputEndDate) \\\n",
    "          .filterBounds(roi_boundary) \\\n",
    "          .map(maskL7cloud)\n",
    "  # print('\\n Original Landsat 7 TOA dataset: \\n',L7.limit(1).getInfo())\n",
    "  # print('Number of images in Landsat 7 TOA dataset: \\t',L7.size().getInfo())\n",
    "\n",
    "  # ------ Landsat 8 TOA\n",
    "  L8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA') \\\n",
    "          .filterDate(inputStartDate, inputEndDate) \\\n",
    "          .filterBounds(roi_boundary) \\\n",
    "          .map(maskL8cloud)\n",
    "  # print('\\n Original Landsat 8 TOA dataset: \\n', L8.limit(1).getInfo())\n",
    "  # print('Number of images in Landsat 8 TOA dataset: \\t',L8.size().getInfo())\n",
    "\n",
    "  # ------ Sentinel-2 TOA\n",
    "  S2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
    "          .filterDate(inputStartDate, inputEndDate) \\\n",
    "          .filterBounds(roi_boundary)  \\\n",
    "          .map(maskS2cloudTOA)\n",
    "  # print('\\n Original Sentinel-2 TOA dataset: \\n',S2.limit(1).getInfo())\n",
    "  # print('Number of images in Sentinel 2 TOA dataset: \\t',S2.size().getInfo())\n",
    "\n",
    "  return L7, L8, S2\n",
    "\n",
    "\n",
    "'''\n",
    "Function to apply model in one direction\n",
    "'''\n",
    "def dir0Regression(img,slopes,intercepts):\n",
    "  return img.select(chastainBandNames).multiply(slopes).add(intercepts)\n",
    "\n",
    "\n",
    "'''\n",
    "Applying the model in the opposite direction\n",
    "'''\n",
    "def dir1Regression(img,slopes,intercepts):\n",
    "  return img.select(chastainBandNames).subtract(intercepts).divide(slopes)\n",
    "\n",
    "\n",
    "'''\n",
    "Function to apply model in one direction\n",
    "'''\n",
    "def dir0Regression(img,slopes,intercepts):\n",
    "  return img.select(chastainBandNames).multiply(slopes).add(intercepts)\n",
    "\n",
    "\n",
    "'''\n",
    "Applying the model in the opposite direction\n",
    "'''\n",
    "def dir1Regression(img,slopes,intercepts):\n",
    "  return img.select(chastainBandNames).subtract(intercepts).divide(slopes)\n",
    "\n",
    "\n",
    "'''\n",
    "Function to correct one sensor to another\n",
    "'''\n",
    "def harmonizationChastain(img, fromSensor,toSensor):\n",
    "  # Get the model for the given from and to sensor\n",
    "  comboKey = fromSensor.upper() + '_' + toSensor.upper()\n",
    "  coeffList = chastainCoeffDict[comboKey]\n",
    "  slopes = coeffList[0]\n",
    "  intercepts = coeffList[1]\n",
    "  direction = ee.Number(coeffList[2])\n",
    "\n",
    "  # Apply the model in the respective direction\n",
    "  out = ee.Algorithms.If(direction.eq(0),dir0Regression(img,slopes,intercepts),dir1Regression(img,slopes,intercepts))\n",
    "  return ee.Image(out).copyProperties(img).copyProperties(img,['system:time_start'])\n",
    "\n",
    "\n",
    "'''\n",
    "Calibrate Landsat-8 (OLI) and Sentinel-2 (MSI) to Landsat-7 (ETM+)\n",
    "'''\n",
    "def Harmonize_L7_L8_S2(L7, L8, S2):\n",
    "  # harmonization\n",
    "  harmonized_L8 = L8.map( lambda img: harmonizationChastain(img, 'OLI','ETM') )\n",
    "  harmonized_S2 = S2.map( lambda img: harmonizationChastain(img, 'MSI','ETM') )\n",
    "\n",
    "  # Merge harmonized landsat-8 and sentinel-2 to landsat-7 image collection\n",
    "  harmonized_LandsatSentinel_ic = ee.ImageCollection(L7.merge(harmonized_L8).merge(harmonized_S2))\n",
    "  # print(harmonized_LandsatSentinel_ic.size().getInfo())\n",
    "  return harmonized_LandsatSentinel_ic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def addNDVI(image):\n",
    "    gcvi = image.select('NIR').divide(image.select('GREEN')).subtract(1).rename('NDVI')\n",
    "    return image.addBands(gcvi).float()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Function definitions to get NDVI values at each 16-day composites\n",
    "'''\n",
    "def Get_NDVI_image_datewise(harmonized_LS_ic):\n",
    "  def get_NDVI_datewise(date):\n",
    "    return harmonized_LS_ic.select(['NDVI']) \\\n",
    "                            .filterDate(ee.Date(date), ee.Date(date).advance(16, 'day')) \\\n",
    "                            .median() \\\n",
    "                            .set('system:time_start',ee.Date(date).millis())\n",
    "  return get_NDVI_datewise\n",
    "\n",
    "def Get_LS_16Day_NDVI_TimeSeries(inputStartDate, inputEndDate, harmonized_LS_ic):\n",
    "  startDate = datetime.strptime(inputStartDate,\"%Y-%m-%d\")\n",
    "  endDate = datetime.strptime(inputEndDate,\"%Y-%m-%d\")\n",
    "\n",
    "  date_list = pd.date_range(start=startDate, end=endDate, freq='16D').tolist()\n",
    "  date_list = ee.List( [datetime.strftime(curr_date,\"%Y-%m-%d\") for curr_date in date_list] )\n",
    "\n",
    "  LSC =  ee.ImageCollection.fromImages(date_list.map(Get_NDVI_image_datewise(harmonized_LS_ic)))\n",
    "\n",
    "  return LSC\n",
    "\n",
    "\n",
    "'''\n",
    "Pair available LSC and modis values for each time stamp.\n",
    "'''\n",
    "def pairLSModis(lsRenameBands):\n",
    "  def pair(feature):\n",
    "    date = ee.Date( feature.get('system:time_start') )\n",
    "    startDateT = date.advance(-8,'day')\n",
    "    endDateT = date.advance(8,'day')\n",
    "\n",
    "    # ------ MODIS VI ( We can add EVI to the band list later )\n",
    "    modis = ee.ImageCollection('MODIS/061/MOD13Q1') \\\n",
    "              .filterDate(startDateT, endDateT) \\\n",
    "              .select(['NDVI','SummaryQA']) \\\n",
    "              .filterBounds(roi_boundary) \\\n",
    "              .median() \\\n",
    "              .rename(['NDVI_modis', 'SummaryQA_modis'])\n",
    "\n",
    "    return feature.rename(lsRenameBands).addBands(modis)\n",
    "  return pair\n",
    "\n",
    "\n",
    "'''\n",
    "Function to get Pearson Correlation Coffecient to perform GapFilling\n",
    "'''\n",
    "def get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, bandList):\n",
    "  corr = LSC_modis_paired_ic.filterBounds(roi_boundary) \\\n",
    "                            .select(bandList).toArray() \\\n",
    "                            .arrayReduce( reducer = ee.Reducer.pearsonsCorrelation(), axes=[0], fieldAxis=1 ) \\\n",
    "                            .arrayProject([1]).arrayFlatten([['c', 'p']])\n",
    "  return corr\n",
    "\n",
    "\n",
    "\n",
    "'''Use print(...) to write to this console.\n",
    "Fill gaps in LSC timeseries using modis data\n",
    "'''\n",
    "def gapfillLSM(LSC_modis_regression_model, LSC_bandName, modis_bandName):\n",
    "  def peformGapfilling(image):\n",
    "    offset = LSC_modis_regression_model.select('offset')\n",
    "    scale = LSC_modis_regression_model.select('scale')\n",
    "    nodata = -1\n",
    "\n",
    "    lsc_image = image.select(LSC_bandName)\n",
    "    modisfit = image.select(modis_bandName).multiply(scale).add(offset)\n",
    "\n",
    "    mask = lsc_image.mask()#update mask needs an input (no default input from the API document)\n",
    "    gapfill = lsc_image.unmask(nodata)\n",
    "    gapfill = gapfill.where(mask.Not(), modisfit)\n",
    "\n",
    "    '''\n",
    "    in SummaryQA,\n",
    "    0: Good data, use with confidence\n",
    "    1: Marginal data, useful but look at detailed QA for more information\n",
    "    2: Pixel covered with snow/ice\n",
    "    3: Pixel is cloudy\n",
    "    '''\n",
    "    qc_m = image.select('SummaryQA_modis').unmask(3)  # missing value is grouped as cloud\n",
    "    w_m  = modisfit.mask().rename('w_m').where(qc_m.eq(0), 0.8)  # default is 0.8\n",
    "    w_m = w_m.where(qc_m.eq(1), 0.5)   # Marginal\n",
    "    w_m = w_m.where(qc_m.gte(2), 0.2) # snow/ice or cloudy\n",
    "\n",
    "    # make sure these modis values are read where there is missing data from LandSat, Sentinel\n",
    "    w_l = gapfill.mask() # default is 1\n",
    "    w_l = w_l.where(mask.Not(), w_m)\n",
    "\n",
    "    return gapfill.addBands(w_l).rename(['gapfilled_'+LSC_bandName,'SummaryQA']) #have NDVI from modis and a summary of clarity for each\n",
    "\n",
    "  return peformGapfilling\n",
    "\n",
    "\n",
    "'''\n",
    "Function to combine LSC with Modis data\n",
    "'''\n",
    "def Combine_LS_Modis(LSC):\n",
    "  lsRenameBands = ee.Image(LSC.first()).bandNames().map( lambda band: ee.String(band).cat('_lsc') )\n",
    "  LSC_modis_paired_ic = LSC.map( pairLSModis(lsRenameBands) )\n",
    "\n",
    "  # Output contains scale, offset i.e. two bands\n",
    "  LSC_modis_regression_model_NDVI = LSC_modis_paired_ic.select(['NDVI_modis', 'NDVI_lsc']) \\\n",
    "                                                        .reduce(ee.Reducer.linearFit())\n",
    "\n",
    "  corr_NDVI = get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, ['NDVI_modis', 'NDVI_lsc'])\n",
    "  LSMC_NDVI = LSC_modis_paired_ic.map(gapfillLSM(LSC_modis_regression_model_NDVI, 'NDVI_lsc', 'NDVI_modis'))\n",
    "\n",
    "  return LSMC_NDVI\n",
    "\n",
    "\n",
    "'''\n",
    "Mask out low quality pixels\n",
    "'''\n",
    "def mask_low_QA(lsmc_image):\n",
    "  low_qa = lsmc_image.select('SummaryQA').neq(0.2)\n",
    "  return lsmc_image.updateMask(low_qa).copyProperties(lsmc_image, ['system:time_start'])\n",
    "\n",
    "\n",
    "'''\n",
    "Add image timestamp to each image in time series\n",
    "'''\n",
    "def add_timestamp(image):\n",
    "  timeImage = image.metadata('system:time_start').rename('timestamp')\n",
    "  timeImageMasked = timeImage.updateMask(image.mask().select(0))\n",
    "  return image.addBands(timeImageMasked)\n",
    "\n",
    "\n",
    "'''\n",
    "Perform linear interpolation on missing values\n",
    "'''\n",
    "def performInterpolation(image):\n",
    "  image = ee.Image(image)\n",
    "  beforeImages = ee.List(image.get('before'))\n",
    "  beforeMosaic = ee.ImageCollection.fromImages(beforeImages).mosaic()\n",
    "  afterImages = ee.List(image.get('after'))\n",
    "  afterMosaic = ee.ImageCollection.fromImages(afterImages).mosaic()\n",
    "\n",
    "  # Interpolation formula\n",
    "  # y = y1 + (y2-y1)*((t – t1) / (t2 – t1))\n",
    "  # y = interpolated image\n",
    "  # y1 = before image\n",
    "  # y2 = after image\n",
    "  # t = interpolation timestamp\n",
    "  # t1 = before image timestamp\n",
    "  # t2 = after image timestamp\n",
    "\n",
    "  t1 = beforeMosaic.select('timestamp').rename('t1')\n",
    "  t2 = afterMosaic.select('timestamp').rename('t2')\n",
    "  t = image.metadata('system:time_start').rename('t')\n",
    "  timeImage = ee.Image.cat([t1, t2, t])\n",
    "  timeRatio = timeImage.expression('(t - t1) / (t2 - t1)', {\n",
    "                  't': timeImage.select('t'),\n",
    "                  't1': timeImage.select('t1'),\n",
    "                  't2': timeImage.select('t2'),\n",
    "              })\n",
    "\n",
    "  interpolated = beforeMosaic.add((afterMosaic.subtract(beforeMosaic).multiply(timeRatio)))\n",
    "  result = image.unmask(interpolated)\n",
    "  fill_value = ee.ImageCollection([beforeMosaic, afterMosaic]).mosaic()\n",
    "  result = result.unmask(fill_value)\n",
    "\n",
    "  return result.copyProperties(image, ['system:time_start'])\n",
    "\n",
    "\n",
    "def interpolate_timeseries(S1_TS):\n",
    "  lsmc_masked = S1_TS.map(mask_low_QA)\n",
    "  filtered = lsmc_masked.map(add_timestamp)\n",
    "\n",
    "  # Time window in which we are willing to look forward and backward for unmasked pixel in time series\n",
    "  timeWindow = 120\n",
    "\n",
    "  # Define a maxDifference filter to find all images within the specified days. Convert days to milliseconds.\n",
    "  millis = ee.Number(timeWindow).multiply(1000*60*60*24)\n",
    "  # Filter says that pick only those timestamps which lie between the 2 timestamps not more than millis difference apart\n",
    "  maxDiffFilter = ee.Filter.maxDifference(\n",
    "                              difference = millis,\n",
    "                              leftField = 'system:time_start',\n",
    "                              rightField = 'system:time_start',\n",
    "                            )\n",
    "\n",
    "  # Filter to find all images after a given image. Compare the image's timstamp against other images.\n",
    "  # Images ahead of target image should have higher timestamp.\n",
    "  lessEqFilter = ee.Filter.lessThanOrEquals(\n",
    "                            leftField = 'system:time_start',\n",
    "                            rightField = 'system:time_start'\n",
    "                          )\n",
    "\n",
    "  # Similarly define this filter to find all images before a given image\n",
    "  greaterEqFilter = ee.Filter.greaterThanOrEquals(\n",
    "                            leftField = 'system:time_start',\n",
    "                            rightField = 'system:time_start'\n",
    "                          )\n",
    "\n",
    "  # Apply first join to find all images that are after the target image but within the timeWindow\n",
    "  filter1 = ee.Filter.And( maxDiffFilter, lessEqFilter )\n",
    "  join1 = ee.Join.saveAll(\n",
    "                  matchesKey = 'after',\n",
    "                  ordering = 'system:time_start',\n",
    "                  ascending = False\n",
    "          )\n",
    "  join1Result = join1.apply(\n",
    "                  primary = filtered,\n",
    "                  secondary = filtered,\n",
    "                  condition = filter1\n",
    "                )\n",
    "\n",
    "  # Apply first join to find all images that are after the target image but within the timeWindow\n",
    "  filter2 = ee.Filter.And( maxDiffFilter, greaterEqFilter )\n",
    "  join2 = ee.Join.saveAll(\n",
    "                  matchesKey = 'before',\n",
    "                  ordering = 'system:time_start',\n",
    "                  ascending = True\n",
    "          )\n",
    "  join2Result = join2.apply(\n",
    "                  primary = join1Result,\n",
    "                  secondary = join1Result,\n",
    "                  condition = filter2\n",
    "                )\n",
    "\n",
    "  interpolated_S1_TS = ee.ImageCollection(join2Result.map(performInterpolation))\n",
    "\n",
    "  return interpolated_S1_TS\n",
    "\n",
    "\n",
    "'''\n",
    "Function Definition to get Padded NDVI LSMC timeseries image for a given ROI\n",
    "'''\n",
    "def Get_Padded_NDVI_TS_Image(startDate, endDate, roi_boundary):\n",
    "  L7, L8, S2 = Get_L7_L8_S2_ImageCollections(startDate, endDate, roi_boundary)\n",
    "\n",
    "  harmonized_LS_ic = Harmonize_L7_L8_S2(L7, L8, S2)\n",
    "  harmonized_LS_ic = harmonized_LS_ic.map(addNDVI)\n",
    "  LSC = Get_LS_16Day_NDVI_TimeSeries(startDate, endDate, harmonized_LS_ic)\n",
    "  LSMC_NDVI = Combine_LS_Modis(LSC)\n",
    "  Interpolated_LSMC_NDVI = interpolate_timeseries(LSMC_NDVI)\n",
    "  final_LSMC_NDVI_TS = Interpolated_LSMC_NDVI.select(['gapfilled_NDVI_lsc']).toBands()\n",
    "  final_LSMC_NDVI_TS = final_LSMC_NDVI_TS.clip(roi_boundary)\n",
    "\n",
    "  input_bands = final_LSMC_NDVI_TS.bandNames()\n",
    "  return final_LSMC_NDVI_TS, input_bands\n",
    "\n",
    "\n",
    "'''\n",
    "Function definition to compute euclidean distance to each cluster centroid\n",
    "features ---> clusters\n",
    "flattened ---> time series image clipped to target area\n",
    "input_bands ---> band names for time series image\n",
    "studyarea ---> geometry of region of interest\n",
    "'''\n",
    "# Function to get distances as required from each pixel to each cluster centroid\n",
    "def Get_Euclidean_Distance(cluster_centroids, roi_timeseries_img, input_bands, roi_boundary):\n",
    "\n",
    "  def wrapper(curr_centroid):\n",
    "    temp_img = ee.Image()\n",
    "    curr_centroid = ee.Feature(curr_centroid).setGeometry(roi_boundary)\n",
    "    temp_fc = ee.FeatureCollection( [curr_centroid] )\n",
    "    class_img = temp_fc.select(['class']).reduceToImage(['class'], ee.Reducer.first()).rename(['class'])\n",
    "    def create_img(band_name):\n",
    "      return temp_fc.select([band_name]).reduceToImage([band_name], ee.Reducer.first()).rename([band_name])\n",
    "\n",
    "    temp_img = input_bands.map(create_img)\n",
    "    empty = ee.Image()\n",
    "    temp_img = ee.Image( temp_img.iterate( lambda img, prev: ee.Image(prev).addBands(img) , empty))\n",
    "\n",
    "    temp_img = temp_img.select(temp_img.bandNames().remove('constant'))\n",
    "    distance = roi_timeseries_img.spectralDistance(temp_img, 'sed')\n",
    "    confidence = ee.Image(1.0).divide(distance).rename(['confidence'])\n",
    "    distance = distance.addBands(confidence)\n",
    "    return distance.addBands(class_img.rename(['class'])).set('class', curr_centroid.get('class'))\n",
    "\n",
    "  return cluster_centroids.map(wrapper)\n",
    "\n",
    "\n",
    "'''\n",
    "Function definition to get final prediction image from distance images\n",
    "'''\n",
    "def Get_final_prediction_image(distance_imgs_list):\n",
    "  # Denominator is an image that is sum of all confidences to each cluster\n",
    "  sum_of_distances = ee.ImageCollection( distance_imgs_list ).select(['confidence']).sum().unmask()\n",
    "  distance_imgs_ic = ee.ImageCollection( distance_imgs_list ).select(['distance','class'])\n",
    "\n",
    "  # array is an image where distance band is an array of distances to each cluster centroid and class band is an array of classes associated with each cluster\n",
    "  array_img = ee.ImageCollection(distance_imgs_ic).toArray()\n",
    "\n",
    "  axes = {'image': 0, 'band':1}\n",
    "  sort = array_img.arraySlice(axes['band'], 0, 1)\n",
    "  sorted = array_img.arraySort(sort)\n",
    "\n",
    "  # take the first image only\n",
    "  values = sorted.arraySlice(axes['image'], 0, 1)\n",
    "  # convert back to an image\n",
    "  min = values.arrayProject([axes['band']]).arrayFlatten([['distance', 'class']])\n",
    "  # Extract the hard classification\n",
    "  predicted_class_img = min.select(1)\n",
    "  predicted_class_img = predicted_class_img.rename(['predicted_label'])\n",
    "\n",
    "  return predicted_class_img\n",
    "\n",
    "\n",
    "def get_cropping_frequency(roi_boundary, startDate, endDate):\n",
    "  cluster_centroids = ee.FeatureCollection('projects/ee-indiasat/assets/L3_LULC_Clusters/Final_Level3_PanIndia_Clusters')\n",
    "  ignore_clusters = [12] # remove invalid clusters\n",
    "  cluster_centroids = cluster_centroids.filter(ee.Filter.Not( ee.Filter.inList('class', ignore_clusters)))\n",
    "\n",
    "  final_LSMC_NDVI_TS, input_bands =  Get_Padded_NDVI_TS_Image(startDate, endDate, roi_boundary)\n",
    "  distance_imgs_list = Get_Euclidean_Distance(cluster_centroids, final_LSMC_NDVI_TS, input_bands, roi_boundary)\n",
    "  final_classified_img = Get_final_prediction_image(distance_imgs_list)\n",
    "\n",
    "  return final_classified_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assets found:\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_12_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_12_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_13_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_13_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_14_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_14_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_15_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_15_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_16_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_16_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_17_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_17_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_18_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_18_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_19_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_19_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_20_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_20_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_21_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_21_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_22_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_22_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_23_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_23_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_24_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_24_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_27_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_27_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_29_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_29_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_2_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_2_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_30_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_30_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_3_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_3_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_4_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_4_SAR_Data_part2\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_5_SAR_Data_part1\n",
      "projects/proj76/assets/Begalavi_2020/2021_Begalavi_5_SAR_Data_part2\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'projects/proj76/assets/Begalavi_2020'\n",
    "\n",
    "# List assets under the folder\n",
    "assets = ee.data.listAssets({'parent': folder_path})\n",
    "asset_list = [item['name'] for item in assets.get('assets', [])]\n",
    "\n",
    "print(\"Assets found:\")\n",
    "for a in asset_list:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8cGSXeAsFfH"
   },
   "source": [
    "# Original Pan-India Cropland Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1700212820597,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "D0xRkg4TsZAg",
    "outputId": "9cb8d49f-d828-43c8-8032-3e0b1a2e4fbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_12_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_12_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_12_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_12_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_13_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_13_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_13_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_13_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_14_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_14_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_14_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_14_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_15_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_15_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_15_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_15_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_16_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_16_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_16_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_16_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_17_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_17_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_17_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_17_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_18_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_18_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_18_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_18_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_19_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_19_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_19_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_19_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_20_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_20_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_20_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_20_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_21_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_21_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_21_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_21_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_22_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_22_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_22_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_22_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_23_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_23_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_23_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_23_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_24_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_24_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_24_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_24_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_27_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_27_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_27_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_27_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_29_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_29_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_29_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_29_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_2_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_2_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_2_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_2_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_30_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_30_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_30_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_30_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_3_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_3_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_3_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_3_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_4_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_4_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_4_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_4_SAR_Data_part2\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_5_SAR_Data_part1\n",
      "Started export for 2021_Begalavi_5_SAR_Data_part1\n",
      "Processing: projects/proj76/assets/Begalavi_2020/2021_Begalavi_5_SAR_Data_part2\n",
      "Started export for 2021_Begalavi_5_SAR_Data_part2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "startDate = '2020-04-01'\n",
    "endDate = '2021-03-31'\n",
    "\n",
    "for asset_path in asset_list:\n",
    "    print(f'Processing: {asset_path}')\n",
    "\n",
    "    try:\n",
    "        croplands = ee.FeatureCollection(asset_path)\n",
    "        roi_boundary = croplands.geometry()\n",
    "\n",
    "        L7, L8, S2 = Get_L7_L8_S2_ImageCollections(startDate, endDate, roi_boundary)\n",
    "        harmonized_LS_ic = Harmonize_L7_L8_S2(L7, L8, S2)\n",
    "        harmonized_LS_ic = harmonized_LS_ic.map(addNDVI)\n",
    "\n",
    "        LSC = Get_LS_16Day_NDVI_TimeSeries(startDate, endDate, harmonized_LS_ic)\n",
    "        LSMC_NDVI = Combine_LS_Modis(LSC)\n",
    "        Interpolated_LSMC_NDVI = interpolate_timeseries(LSMC_NDVI)\n",
    "\n",
    "        final_LSMC_NDVI_TS = Interpolated_LSMC_NDVI.select(['gapfilled_NDVI_lsc']).toBands()\n",
    "        final_LSMC_NDVI_TS = final_LSMC_NDVI_TS.clip(roi_boundary)\n",
    "\n",
    "        train_set = final_LSMC_NDVI_TS.sampleRegions(\n",
    "            collection=croplands,\n",
    "            scale=30,\n",
    "            geometries=False\n",
    "        )\n",
    "\n",
    "        file_prefix = asset_path.split(\"/\")[-1]\n",
    "\n",
    "        task = ee.batch.Export.table.toDrive(\n",
    "            collection=train_set,\n",
    "            folder='2020_21_GCVI_SAR',\n",
    "            description=f'GCVI_{file_prefix}',\n",
    "            fileNamePrefix=f'{file_prefix}_GCVI',\n",
    "            fileFormat='CSV',\n",
    "        )\n",
    "\n",
    "        task.start()\n",
    "        print(f'Started export for {file_prefix}')\n",
    "        time.sleep(2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error with {asset_path}: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAvla2TZhgjq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

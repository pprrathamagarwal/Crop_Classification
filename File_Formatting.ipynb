{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a80e1e",
   "metadata": {},
   "source": [
    "# All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8705c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import ast  # To convert string representation of list to actual list\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383b52d6",
   "metadata": {},
   "source": [
    "# Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c3705da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows removed and file updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"Karnataka_Datasets/Across/Begalavi/Begalavi.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Save it back to the same file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Duplicate rows removed and file updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7727fa",
   "metadata": {},
   "source": [
    "# Mapping Points to Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f296d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = gpd.read_file(\"Karnataka_Datasets/Indian_districts_boundary.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13fd7f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial join completed. Output saved to 'output_with_districts.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load the CSV file (latitude and longitude points)\n",
    "points_df = pd.read_csv(\"Karnataka_Datasets/Crops_Karnataka.csv\")\n",
    "\n",
    "# Ensure the CSV contains 'latitude' and 'longitude' columns\n",
    "if not {'latitude', 'longitude'}.issubset(points_df.columns):\n",
    "    raise ValueError(\"CSV must contain 'latitude' and 'longitude' columns.\")\n",
    "\n",
    "# Step 3: Convert points to a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(points_df['longitude'], points_df['latitude'])]\n",
    "points_gdf = gpd.GeoDataFrame(points_df, geometry=geometry, crs=districts.crs)\n",
    "\n",
    "# Step 4: Perform spatial join to find districts for each point\n",
    "result = gpd.sjoin(points_gdf, districts, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "# Step 5: Save the result to a new CSV\n",
    "result.to_csv(\"Karnataka_Datasets/Crops_Karnataka_With_Districts.csv\", index=False)\n",
    "\n",
    "print(\"Spatial join completed. Output saved to 'output_with_districts.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5bc72",
   "metadata": {},
   "source": [
    "# Removing Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63c39cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnecessary columns removed and file updated successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "file_path = \"Karnataka_Datasets/Crops_Karnataka_With_Districts.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# List of columns to remove\n",
    "columns_to_remove = [\"CropSurveyDate\",\"Crop_Extent\",\"District_Name\",\"District_code\",\n",
    "                     \"Hobli_Name\",\"Hobli_code\",\"Image_url\",\"Month\",\"Season\",\"Season_code\",\"Survey_id\",\n",
    "                     \"Taluk_Name\",\"Taluk_code\",\"Village_Name\",\"Village_code\",\"Weekname\",\"Year_code\",\"Years\",\n",
    "                     \"index_right\",\"snippet\",\"visibility\",\"extrude\",\"descriptio\",\"tessellate\",\"drawOrder\",\"icon\",\"end\",\"begin\",\n",
    "                     \"altitudeMo\",\"timestamp\"\n",
    "]  # Replace with actual column names\n",
    "\n",
    "# Drop the columns if they exist\n",
    "df = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "# Save it back to the same file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Unnecessary columns removed and file updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f8419",
   "metadata": {},
   "source": [
    "# Print Count Of Each District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea26c599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height\n",
      "Tall      7647\n",
      "Medium    6724\n",
      "Short     6119\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"Karnataka_Datasets/Across/Train_Test_Datasets/Combined_Train_Balanced_Structure.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Count occurrences of each unique value in the \"Name\" column\n",
    "name_counts = df[\"Height\"].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(name_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f0ac7",
   "metadata": {},
   "source": [
    "# Filter Out Bangalore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d44b087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with Name = 'Bangalore' have saved to 'Karnataka_Datasets/Crops_Karnataka_Bangalore.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "file_path = \"Karnataka_Datasets/Crops_Karnataka_With_Districts.csv\"  # Replace with your actual file path\n",
    "output_file = \"Karnataka_Datasets/Crops_Karnataka_Bangalore.csv\"  # Specify the new file name\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter out rows where Name is \"Bangalore\"\n",
    "df = df[df[\"Name\"] == \"Bangalore\"]\n",
    "\n",
    "# Save it to a different file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Rows with Name = 'Bangalore' have saved to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f70476",
   "metadata": {},
   "source": [
    "# Keep A Count of Each Cropname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26bdc28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height\n",
      "Short     5300\n",
      "Medium    1275\n",
      "Tall        63\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"Karnataka_Datasets/Across/Kharif/Bellari/Bellari_SAR_NDVI_Interpolated.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Count occurrences of each unique value in the \"Name\" column\n",
    "name_counts = df[\"Height\"].value_counts()\n",
    "pd.set_option('display.max_rows', None)\n",
    "# Print the counts\n",
    "print(name_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f31015",
   "metadata": {},
   "source": [
    "# Get A Count of Each Duration Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3284ed68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration_numeric\n",
      "1    9259\n",
      "3    5944\n",
      "2    5228\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"Karnataka_Datasets/District_Data_NDVI_5Day/Merged/Karnataka_Scaled_Normalized_Mapped.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Count occurrences of each unique value in the \"Name\" column\n",
    "name_counts = df[\"duration_numeric\"].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(name_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e18aa25",
   "metadata": {},
   "source": [
    "# Sample Random Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66396646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset saved to 'Karnataka_Datasets/Bangalore/Crops_Karnataka_Bangalore_Sampled_On_Duration.csv' with improved distribution.\n"
     ]
    }
   ],
   "source": [
    "# Load the filtered crops dataset\n",
    "input_file = \"Karnataka_Datasets/Bangalore/Crops_Karnataka_Bangalore_Filtered.csv\"  # Use the previously generated file\n",
    "output_file = \"Karnataka_Datasets/Bangalore/Crops_Karnataka_Bangalore_Sampled_On_Duration.csv\"  # New file to save the sampled data\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Separate by Duration\n",
    "df_low = df[df[\"Duration\"] == \"Low\"]\n",
    "df_medium = df[df[\"Duration\"] == \"Medium\"]\n",
    "df_long = df[df[\"Duration\"] == \"Long\"]\n",
    "\n",
    "# Get unique low-duration crop counts\n",
    "low_crop_counts = df_low[\"Cropname\"].value_counts()\n",
    "\n",
    "# Define sample size for Low crops\n",
    "target_low_samples = 11000\n",
    "\n",
    "# Step 1: Take all samples from small \"Low\" crops first (excluding Ragi)\n",
    "small_low_crops = [\"Bajra\", \"Potato\", \"Redgram\"]  # Prioritized small crops\n",
    "selected_low = []\n",
    "remaining_samples = target_low_samples\n",
    "\n",
    "for crop in small_low_crops:\n",
    "    if crop in low_crop_counts:\n",
    "        crop_data = df_low[df_low[\"Cropname\"] == crop]\n",
    "        selected_low.append(crop_data)\n",
    "        remaining_samples -= len(crop_data)\n",
    "\n",
    "# Step 2: If space remains, sample proportionally from other Low crops (except Ragi)\n",
    "other_low_crops = df_low[~df_low[\"Cropname\"].isin([\"Ragi\"] + small_low_crops)]\n",
    "if remaining_samples > 0 and not other_low_crops.empty:\n",
    "    sampled_other = other_low_crops.sample(n=min(remaining_samples, len(other_low_crops)), random_state=42)\n",
    "    selected_low.append(sampled_other)\n",
    "    remaining_samples -= len(sampled_other)\n",
    "\n",
    "# Step 3: If space is still left, add Ragi to reach 11,000\n",
    "if remaining_samples > 0:\n",
    "    ragi_sample = df_low[df_low[\"Cropname\"] == \"Ragi\"].sample(n=remaining_samples, random_state=42)\n",
    "    selected_low.append(ragi_sample)\n",
    "\n",
    "# Merge selected low-duration crops\n",
    "df_low_sampled = pd.concat(selected_low, ignore_index=True)\n",
    "\n",
    "# Combine all durations together\n",
    "df_final = pd.concat([df_low_sampled, df_medium, df_long], ignore_index=True)\n",
    "\n",
    "# Save the final balanced dataset\n",
    "df_final.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Balanced dataset saved to '{output_file}' with improved distribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36178c8b",
   "metadata": {},
   "source": [
    "# Height and Duration Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80ade6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File updated successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('Katihar/Katihar_5Day.csv')\n",
    "\n",
    "crop_mapping = {\n",
    "    'Bajra': ('Short', 'Low'),\n",
    "    'Banana': ('Tall', 'Long'),\n",
    "    'Coconut': ('Tall', 'Long'),\n",
    "    'Jowar': ('Medium', 'Low'),\n",
    "    'Maize': ('Medium', 'Medium'),\n",
    "    'Paddy': ('Short', 'Medium'),\n",
    "    'Potato': ('Short', 'Medium'),\n",
    "    'Ragi': ('Short', 'Low'),\n",
    "    'Redgram': ('Medium', 'Medium'),\n",
    "    'Wheat': ('Short', 'Low'),\n",
    "    'Eucalyptus': ('Tall', 'Long'),\n",
    "    'Rose': ('Short', 'Medium'),\n",
    "    'HariMirch': ('Short', 'Low'),\n",
    "    'Eknayaka': ('Short', 'Medium'),\n",
    "    'Chow Chow': ('Medium', 'Medium'),\n",
    "    'Beans': ('Short', 'Low'),\n",
    "    'Ridgegourd': ('Medium', 'Medium'),\n",
    "    'Bottlegourd': ('Medium', 'Medium'),\n",
    "    'Marigold': ('Short', 'Medium'),\n",
    "    'Gerbera': ('Short', 'Medium'),\n",
    "    'Chrysanthemum': ('Short', 'Medium'),\n",
    "    'Tomato': ('Short', 'Medium'),\n",
    "    'Horsegram': ('Medium', 'Medium'),\n",
    "    'Avare': ('Medium', 'Medium'),\n",
    "    'Coriander': ('Short', 'Low'),\n",
    "    'Silver Oak': ('Tall', 'Long'),\n",
    "    'Neem': ('Tall', 'Long'),\n",
    "    'Guava': ('Medium', 'Long'),\n",
    "    'Dahlia': ('Short', 'Medium'),\n",
    "    'Trees': ('Tall', 'Long'),\n",
    "    'Elephantfoot_Yam': ('Medium', 'Long'),\n",
    "    'Malabar Neem': ('Tall', 'Long'),\n",
    "    'Sweetcorn': ('Medium', 'Medium'),\n",
    "    'Cucumber': ('Medium', 'Medium'),\n",
    "    'Carrot': ('Short', 'Medium'),\n",
    "    'Mangoes': ('Tall', 'Long'),\n",
    "    'Makkachari': ('Short', 'Low'),\n",
    "    'Flower': ('Short', 'Medium'),\n",
    "    'Cabbage': ('Short', 'Medium'),\n",
    "    'Asparagus': ('Short', 'Medium'),\n",
    "    'Teak': ('Tall', 'Long'),\n",
    "    'Drumstick': ('Medium', 'Long'),\n",
    "    'Vegetables': ('Short', 'Medium'),\n",
    "    'Beetroot': ('Short', 'Medium'),\n",
    "    'Cauliflower': ('Short', 'Medium'),\n",
    "    'Mint': ('Short', 'Low'),\n",
    "    'Methi Leaves': ('Short', 'Low'),\n",
    "    'Dill': ('Short', 'Low'),\n",
    "    'Noni': ('Medium', 'Long'),\n",
    "    'Ivygourd': ('Medium', 'Medium'),\n",
    "    'Brinjal': ('Short', 'Medium'),\n",
    "    'Green Fodder': ('Medium', 'Medium'),\n",
    "    'Acacia': ('Tall', 'Long'),\n",
    "    'Arecanut': ('Tall', 'Long'),\n",
    "    'Papaya': ('Medium', 'Long'),\n",
    "    'Chiku': ('Tall', 'Long'),\n",
    "    'Fruits': ('Medium', 'Long'),\n",
    "    'Spinach': ('Short', 'Low'),\n",
    "    'Grapes': ('Medium', 'Long'),\n",
    "    'Fennel': ('Short', 'Low'),\n",
    "    'Capsicum': ('Short', 'Medium'),\n",
    "    'Bittergourd': ('Medium', 'Medium'),\n",
    "    'Mulberry': ('Medium', 'Long'),\n",
    "    'Knolkhol': ('Short', 'Medium'),\n",
    "    'Crossandra': ('Short', 'Medium'),\n",
    "    'Agaves': ('Tall', 'Long'),\n",
    "    'Gladiolus': ('Short', 'Medium'),\n",
    "    'BlackPepper': ('Tall', 'Long'),\n",
    "    'Groundnut': ('Short', 'Long'),\n",
    "    'Barley': ('Short', 'Low'),\n",
    "    'Tuberose': ('Short', 'Medium'),\n",
    "    'Lemon': ('Medium', 'Long'),\n",
    "    'Sugarcane': ('Tall', 'Long'),\n",
    "    'Peas': ('Short', 'Medium'),\n",
    "    'Indigo': ('Medium', 'Medium'),\n",
    "    'China Aster': ('Short', 'Medium'),\n",
    "    'LadyFinger': ('Short', 'Medium'),\n",
    "    'Vegetable Cowpea': ('Short', 'Low'),\n",
    "    'Harimirch': ('Short', 'Low'),\n",
    "    'Dhavana': ('Short', 'Low'),\n",
    "    'Tamarind': ('Tall', 'Long'),\n",
    "    'Turmeric': ('Short', 'Long'),\n",
    "    'Cowpea': ('Short', 'Low'),\n",
    "    'Dolichuous_Bean': ('Medium', 'Medium'),\n",
    "    'Pumpkin': ('Medium', 'Medium'),\n",
    "    'Broccoli': ('Short', 'Medium'),\n",
    "    'Sunflower': ('Medium', 'Medium'),\n",
    "    'Sweet Corn': ('Medium', 'Medium'),\n",
    "    'Rose Wood': ('Tall', 'Long'),\n",
    "    'Baby Corn': ('Medium', 'Low'),\n",
    "    'Ginger': ('Short', 'Long'),\n",
    "    'Sweet Potato': ('Short', 'Long'),\n",
    "    'Shimp Nut': ('Medium', 'Medium'),\n",
    "    'Snakegourd': ('Medium', 'Medium'),\n",
    "    'Pomegranate': ('Medium', 'Long'),\n",
    "    'Jamun': ('Tall', 'Long'),\n",
    "    'Greengram': ('Short', 'Low'),\n",
    "    'Cashewnuts': ('Tall', 'Long'),\n",
    "    'Saffron': ('Short', 'Low'),\n",
    "    'Chive': ('Short', 'Low'),\n",
    "    'Mahagani Tree': ('Tall', 'Long'),\n",
    "    'Casuarina Tree': ('Tall', 'Long'),\n",
    "    'Bluegrapes': ('Medium', 'Long'),\n",
    "    'Jasmine Pubescens': ('Short', 'Medium'),\n",
    "    'Gram': ('Short', 'Low'),\n",
    "    'Grapes Seedless': ('Medium', 'Long'),\n",
    "    'Ashgourd': ('Medium', 'Medium'),\n",
    "    'Nigerseed': ('Short', 'Low'),\n",
    "    'Jackfruit': ('Tall', 'Long'),\n",
    "    'Sandalwood': ('Tall', 'Long'),\n",
    "    'Linseed': ('Short', 'Low'),\n",
    "    'Curry Leaves': ('Short', 'Low'),\n",
    "    'Wheat': ('Short', 'Low'),\n",
    "    'Mustard': ('Short', 'Low'),\n",
    "    'Maize': ('Medium', 'Medium'),\n",
    "    'Sugarcane': ('Tall', 'Long'),\n",
    "    'Lentil': ('Short', 'Medium'),\n",
    "    'Rice': ('Short', 'Medium'),\n",
    "    'Gram': ('Short', 'Low'),\n",
    "    'Garlic': ('Short', 'Medium'),\n",
    "    'Potato': ('Short', 'Medium'),\n",
    "    'Green pea': ('Short', 'Medium'),\n",
    "    'Bersem': ('Short', 'Medium'),\n",
    "    'Coriander': ('Short', 'Low'),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "height_mapping = {'Short': 1, 'Medium': 2, 'Tall': 3}\n",
    "duration_mapping = {'Low': 1, 'Medium': 2, 'Long': 3}\n",
    "\n",
    "# Apply the mapping to the DataFrame\n",
    "df[['Height', 'Duration']] = df['Crop_Name'].map(crop_mapping).apply(pd.Series)\n",
    "df['height_numeric'] = df['Height'].map(height_mapping)\n",
    "df['duration_numeric'] = df['Duration'].map(duration_mapping)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv('Katihar/Katihar_5Day.csv', index=False)\n",
    "\n",
    "print(\"File updated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28429ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¢ Time steps per point (Top 10):\n",
      "    Latitude  Longitude  TimeSteps\n",
      "0  13.086502  77.475513         70\n",
      "1  13.086503  77.475486         70\n",
      "2  13.086532  77.473382         70\n",
      "3  13.086533  77.473390         70\n",
      "4  13.086534  77.473396         70\n",
      "5  13.086914  77.472185         70\n",
      "6  13.086940  77.472175         70\n",
      "7  13.086987  77.475678         70\n",
      "8  13.086998  77.472010         70\n",
      "9  13.087005  77.471977         70\n",
      "\n",
      "ðŸ“ˆ Max time steps for any point: 70\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv('Karnataka_Datasets/Across/Sample/Karnataka_Chunk_10_90.csv')\n",
    "\n",
    "# Convert 'Date' to datetime (format: DD-MM-YYYY)\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
    "\n",
    "# Drop duplicates to avoid extra time steps\n",
    "df = df.drop_duplicates(subset=['Latitude', 'Longitude', 'Date'])\n",
    "\n",
    "# Sort by Latitude, Longitude, and Date\n",
    "df = df.sort_values(by=['Latitude', 'Longitude', 'Date'])\n",
    "\n",
    "# Set multi-index for easy grouping\n",
    "df.set_index(['Latitude', 'Longitude', 'Date'], inplace=True)\n",
    "\n",
    "# Columns of interest for vegetation indices and bands\n",
    "columns_of_interest = ['NDVI', 'B11', 'B12', 'B3', 'B4', 'B8', 'B8A', 'GCVI']\n",
    "\n",
    "# Bring 'Date' back as a column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Recalculate TimeIndex using date ranking per point\n",
    "df['TimeIndex'] = df.groupby(['Latitude', 'Longitude'])['Date'].rank(method='first').astype(int)\n",
    "\n",
    "# Melt the dataframe to long format for pivoting\n",
    "df_melt = df.melt(id_vars=['Latitude', 'Longitude', 'TimeIndex'], \n",
    "                  value_vars=columns_of_interest, \n",
    "                  var_name='Variable', \n",
    "                  value_name='Value')\n",
    "\n",
    "# Create a new DataFrame that represents every possible (Lat, Lon, TimeIndex) combination\n",
    "max_time_index = df['TimeIndex'].max()\n",
    "time_index_range = pd.DataFrame({'TimeIndex': range(1, max_time_index + 1)})\n",
    "\n",
    "# Create a grid of every Latitude, Longitude and TimeIndex combination\n",
    "lat_lon_combinations = df[['Latitude', 'Longitude']].drop_duplicates()\n",
    "full_grid = pd.merge(lat_lon_combinations, time_index_range, how='cross')\n",
    "\n",
    "# Merge the original melted DataFrame with the full grid to ensure all time indices\n",
    "df_full = pd.merge(full_grid, df_melt, on=['Latitude', 'Longitude', 'TimeIndex'], how='left')\n",
    "\n",
    "# Pivot to get variables as columns (VI/Band_timeIndex)\n",
    "df_pivot = df_full.pivot(index=['Latitude', 'Longitude'], \n",
    "                         columns=['Variable', 'TimeIndex'], \n",
    "                         values='Value')\n",
    "\n",
    "# Reindex columns to ensure all (Variable, TimeIndex) combos exist\n",
    "full_column_index = pd.MultiIndex.from_product(\n",
    "    [columns_of_interest, range(1, max_time_index + 1)],\n",
    "    names=['Variable', 'TimeIndex']\n",
    ")\n",
    "df_pivot = df_pivot.reindex(columns=full_column_index)\n",
    "\n",
    "# Flatten the multi-level columns to something more readable\n",
    "df_pivot.columns = [f'{var}_{i}' for var, i in df_pivot.columns]\n",
    "\n",
    "# Reset the index for final output\n",
    "df_pivot = df_pivot.reset_index()\n",
    "\n",
    "# Merge Crop_Name back to the dataset\n",
    "crop_name_df = df[['Latitude', 'Longitude', 'Crop_Name']].drop_duplicates()\n",
    "df_pivot = df_pivot.merge(crop_name_df, on=['Latitude', 'Longitude'], how='left')\n",
    "\n",
    "# Save the final result\n",
    "df_pivot.to_csv('Karnataka_Datasets/', index=False)\n",
    "\n",
    "# Optional: Print counts of available time steps per (Latitude, Longitude) pair\n",
    "point_counts = df.groupby(['Latitude', 'Longitude']).size().reset_index(name='TimeSteps')\n",
    "print(\"\\nðŸ”¢ Time steps per point (Top 10):\")\n",
    "print(point_counts.head(10))\n",
    "\n",
    "# Optional: Check max time steps\n",
    "print(f\"\\nðŸ“ˆ Max time steps for any point: {point_counts['TimeSteps'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b402db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing: Karnataka_Chunk_10_QA.csv\n",
      "ðŸ“‚ Processing: Karnataka_Chunk_1_QA.csv\n",
      "ðŸ“‚ Processing: Karnataka_Chunk_2_QA.csv\n",
      "ðŸ“‚ Processing: Karnataka_Chunk_3_QA.csv\n",
      "ðŸ“‚ Processing: Karnataka_Chunk_4_QA.csv\n",
      "ðŸ“‚ Processing: Karnataka_Chunk_5_QA.csv\n",
      "ðŸ“‚ Processing: Karnataka_Chunk_6_QA.csv\n",
      "ðŸ“‚ Processing: Karnataka_Chunk_7_QA.csv\n",
      "ðŸ“‚ Processing: Karnataka_Chunk_8_QA.csv\n",
      "ðŸ“‚ Processing: Karnataka_Chunk_9_QA.csv\n",
      "\n",
      "âœ… All files processed and saved to: Karnataka_Datasets/Across_QA/90/Karnataka_Merged_S2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def process_file(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Parse date\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='mixed', dayfirst=True, errors='coerce')\n",
    "\n",
    "    # Drop duplicates\n",
    "    df = df.drop_duplicates(subset=['Latitude', 'Longitude', 'Date'])\n",
    "\n",
    "    # Sort and reset index\n",
    "    df = df.sort_values(by=['Latitude', 'Longitude', 'Date'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Assign TimeIndex per (Latitude, Longitude) using date rank\n",
    "    df['TimeIndex'] = df.groupby(['Latitude', 'Longitude'])['Date'].rank(method='first').astype(int)\n",
    "\n",
    "    # Columns to use\n",
    "    columns_of_interest = ['NDVI', 'B11', 'B12', 'B3', 'B4', 'B8', 'B8A', 'GCVI']\n",
    "\n",
    "    # Melt to long format\n",
    "    df_melt = df.melt(id_vars=['Latitude', 'Longitude', 'TimeIndex'], \n",
    "                      value_vars=columns_of_interest, \n",
    "                      var_name='Variable', \n",
    "                      value_name='Value')\n",
    "\n",
    "    # Prepare full grid to ensure all time indices are retained\n",
    "    max_time_index = df['TimeIndex'].max()\n",
    "    time_index_range = pd.DataFrame({'TimeIndex': range(1, max_time_index + 1)})\n",
    "    lat_lon_combinations = df[['Latitude', 'Longitude']].drop_duplicates()\n",
    "    full_grid = pd.merge(lat_lon_combinations, time_index_range, how='cross')\n",
    "\n",
    "    df_full = pd.merge(full_grid, df_melt, on=['Latitude', 'Longitude', 'TimeIndex'], how='left')\n",
    "\n",
    "    # Pivot: one column per variable per time step\n",
    "    df_pivot = df_full.pivot(index=['Latitude', 'Longitude'], \n",
    "                             columns=['Variable', 'TimeIndex'], \n",
    "                             values='Value')\n",
    "\n",
    "    # Reindex columns for missing combinations\n",
    "    full_column_index = pd.MultiIndex.from_product(\n",
    "        [columns_of_interest, range(1, max_time_index + 1)],\n",
    "        names=['Variable', 'TimeIndex']\n",
    "    )\n",
    "    df_pivot = df_pivot.reindex(columns=full_column_index)\n",
    "\n",
    "    # Flatten column names\n",
    "    df_pivot.columns = [f'{var}_{i}' for var, i in df_pivot.columns]\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "\n",
    "    # Merge crop name back\n",
    "    crop_name_df = df[['Latitude', 'Longitude', 'Crop_Name']].drop_duplicates()\n",
    "    df_pivot = df_pivot.merge(crop_name_df, on=['Latitude', 'Longitude'], how='left')\n",
    "\n",
    "    return df_pivot\n",
    "\n",
    "\n",
    "# === Main logic ===\n",
    "\n",
    "input_dir = 'Karnataka_Datasets/Across_QA/90/'  # change this as needed\n",
    "output_path = os.path.join(input_dir, 'Karnataka_Merged_S2.csv')\n",
    "\n",
    "# List all CSV files\n",
    "csv_files = glob(os.path.join(input_dir, '*.csv'))\n",
    "\n",
    "# List to hold all processed DataFrames\n",
    "processed_list = []\n",
    "\n",
    "# Process each CSV\n",
    "for file in csv_files:\n",
    "    print(f'ðŸ“‚ Processing: {os.path.basename(file)}')\n",
    "    processed_df = process_file(file)\n",
    "    processed_list.append(processed_df)\n",
    "\n",
    "# Merge all processed files\n",
    "final_df = pd.concat(processed_list, ignore_index=True)\n",
    "\n",
    "# Save final merged result\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(f'\\nâœ… All files processed and saved to: {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22c43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
